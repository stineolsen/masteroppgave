{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import heartpy as hp\n",
    "# from pyhrv import time_domain\n",
    "# from pyhrv import hrv\n",
    "# import pyhrv\n",
    "\n",
    "# %matplotlib agg\n",
    "\n",
    "\n",
    "# import os\n",
    "# os.chdir('C:/Users/Olsen/Desktop/Masteroppgave/Data/fitfiler/candidate1/HRV_export')\n",
    "# txt_file_path= 'candidate1_HRV_2023-05-18_rowing_3.0.csv'\n",
    "\n",
    "# # Load your data from the txt file\n",
    "# # data = pd.read_csv('p1.txt', delimiter='\\t', header=None, names=['time_elapsed', 'ibi'])\n",
    "# txt_data = pd.read_csv(txt_file_path, sep=',', header='infer')  \n",
    "\n",
    "# # with open('p1.txt') as f:\n",
    "# #     lines = f.readlines()\n",
    "# #     time_elapsed = np.array([line.split()[0] for line in lines])\n",
    "# #     ibi = np.array([line.split()[1] for line in lines])\n",
    "# # time_elapsed = time_elapsed.astype(np.float64)\n",
    "# # ibi = ibi.astype(np.float64)\n",
    "\n",
    "\n",
    "# # data_dict = {'time_elapsed': time_elapsed[2395:], 'ibi': ibi[2395:]}\n",
    "# # data = pd.DataFrame(data_dict)\n",
    "# # print(data['time_elapsed'])\n",
    "# # data['time_elapsed'] = np.array(data['time_elapsed']/60)\n",
    "\n",
    "# txt_data['timestamp'] = np.array(txt_data['timestamp']/60)\n",
    "\n",
    "# # Assuming your time_elapsed is in seconds\n",
    "# fs = 1 / np.mean(np.diff(txt_data['timestamp']))\n",
    "\n",
    "\n",
    "# # nni = pyhrv.utils.load_sample_nni()\n",
    "\n",
    "# # Function to compute HRV features on a 5-minute moving window\n",
    "# def compute_hrv_features(ibis):\n",
    "#     hrv_sample = time_domain.nni_parameters(ibis)\n",
    "#     return hrv_sample['nni_mean']\n",
    "\n",
    "# # Initialize variables\n",
    "# window_size = int(fs) * 5  # 5 minutes in minuttes\n",
    "# num_samples = len(txt_data['hrv'])\n",
    "# hrv_samples = []\n",
    "\n",
    "# # Iterate through the IBI array with a 5-minute moving window\n",
    "# for i in range(num_samples - window_size + 1):\n",
    "#     window = txt_data.iloc[i:i+window_size]\n",
    "#     window_data=window['hrv']\n",
    "#     window_time = window['timestamp']\n",
    "\n",
    "#     # print(window_time)\n",
    "#     # print(window_data.values)\n",
    "#     hrv_sample = compute_hrv_features(window_data)\n",
    "#     hrv_samples.append(hrv_sample)\n",
    "\n",
    "# # Display or save the HRV samples as needed\n",
    "# for i, hrv_sample in enumerate(hrv_samples):\n",
    "#     print(f'HRV Sample {i+1}: {hrv_sample}')\n",
    "\n",
    "\n",
    "# print('Mean all HRV ', np.mean(hrv_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import heartpy as hp\n",
    "# import pyhrv.time_domain as td\n",
    "# from pyhrv import hrv\n",
    "# import pyhrv\n",
    "# import glob\n",
    "\n",
    "# import os\n",
    "\n",
    "\n",
    "# os.chdir('C:/Users/Olsen/Desktop/Masteroppgave/Data/fitfiler/candidate1/HRV_export/test')\n",
    "\n",
    "# files = glob.glob('*.csv')  # Adjust the path as needed\n",
    "\n",
    "# # Function to compute HRV features on a 5-minute moving window\n",
    "# def compute_hrv_features(ibis):\n",
    "#     hrv_sample = td.time_domain(ibis)\n",
    "#     return hrv_sample['nni_mean']\n",
    "\n",
    "\n",
    "# result=pd.DataFrame({'mean_RR':[], 'file': [], 'candidate': [], 'feeling': []})\n",
    "\n",
    "# for file in files: \n",
    "#     print(file)\n",
    "#     txt_data = pd.read_csv(file, sep=',', header='infer')  \n",
    "\n",
    "#     txt_data['timestamp'] = np.array(txt_data['timestamp']/60)\n",
    "\n",
    "#     # Assuming your time_elapsed is in seconds\n",
    "#     fs = 1 / np.mean(np.diff(txt_data['timestamp']))\n",
    "\n",
    "#     # Initialize variables\n",
    "#     window_size = int(fs) * 5  # 5 minutes in minuttes\n",
    "#     num_samples = len(txt_data['hrv'])\n",
    "#     hrv_samples = []\n",
    "#     temp_result=pd.DataFrame()\n",
    "\n",
    "#     # Iterate through the IBI array with a 5-minute moving window\n",
    "#     for i in range(num_samples - window_size + 1):\n",
    "#         window = txt_data.iloc[i:i+window_size]\n",
    "#         window_data=window['hrv']\n",
    "#         window_time = window['timestamp']\n",
    "\n",
    "#         # print(window_time)\n",
    "#         # print(window_data.values)\n",
    "#         hrv_sample = compute_hrv_features(window_data)\n",
    "#         hrv_samples.append(hrv_sample)\n",
    "\n",
    "#     temp_result['mean_RR'] = hrv_samples\n",
    "#     temp_result['file'] = file\n",
    "#     temp_result['candidate'] = 1\n",
    "#     temp_result['feeling'] = txt_data['feeling'][0]\n",
    "#     result = result.append(temp_result)\n",
    "\n",
    "#     print(result.shape)\n",
    "#     # Display or save the HRV samples as needed\n",
    "#     # for i, hrv_sample in enumerate(hrv_samples):\n",
    "#     #     print(f'HRV Sample {i+1}: {hrv_sample}')\n",
    "\n",
    "\n",
    "# print('Mean all HRV ', np.mean(hrv_samples))\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyhrv import time_domain, frequency_domain, nonlinear\n",
    "import hfda\n",
    "import tsfel\n",
    "from scipy.stats import skew \n",
    "from scipy.stats import kurtosis \n",
    "from hrvanalysis import get_frequency_domain_features, get_sampen\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib agg\n",
    "\n",
    "\n",
    "\n",
    "def calculate_hrv_features_pyhrv(rr_intervals):\n",
    "    # Convert RR intervals to milliseconds\n",
    "    rr_intervals_ms = np.array(rr_intervals)\n",
    "\n",
    "    # Time domain features\n",
    "    time_domain_features = time_domain.time_domain(rr_intervals_ms, threshold=25)\n",
    "    sdsd_feature = time_domain.sdsd(rr_intervals)\n",
    "    kurt_feature = kurtosis(rr_intervals_ms)\n",
    "    skew_feature= skew(rr_intervals_ms)\n",
    "\n",
    "\n",
    "    # Frequency domain features\n",
    "    frequency_domain_features_anlysis = get_frequency_domain_features(rr_intervals_ms)\n",
    "\n",
    "    # Nonlinear features\n",
    "    nonlinear_features = nonlinear.poincare(rr_intervals_ms)\n",
    "\n",
    "    # Additional features\n",
    "    sampen_value= get_sampen(rr_intervals_ms)\n",
    "\n",
    "    # higuci_value = hfda.measure(rr_intervals, 5)\n",
    "\n",
    "    # Combine all features into a dictionary\n",
    "    hrv_features = {\n",
    "        'MEAN_RR': time_domain_features['nni_mean'],\n",
    "        'MEDIAN_RR': np.median(rr_intervals),\n",
    "        'SDRR': time_domain_features['sdnn'],\n",
    "        'RMSS': time_domain_features['rmssd'],\n",
    "        'SDSD': sdsd_feature['sdsd'],\n",
    "        'SDRR_RMSSD': time_domain_features['sdnn'] / time_domain_features['rmssd'],\n",
    "        'HR': 60000 / time_domain_features['nni_mean'],\n",
    "        'pNN25': time_domain_features['pnn25'],\n",
    "        'pNN50': time_domain_features['pnn50'],\n",
    "        'SD1': nonlinear.poincare(rr_intervals_ms)['sd1'],\n",
    "        'SD2': nonlinear.poincare(rr_intervals_ms)['sd2'],\n",
    "        'KURT': kurt_feature,\n",
    "        'SKEW': skew_feature,\n",
    "        'VLF': frequency_domain_features_anlysis['vlf'],\n",
    "        'VLF_PCT': frequency_domain_features_anlysis['vlf']*100 / frequency_domain_features_anlysis['total_power'],  \n",
    "        'LF': frequency_domain_features_anlysis['lf'],\n",
    "        'LF_PCT': frequency_domain_features_anlysis['lf']*100 / frequency_domain_features_anlysis['total_power'],\n",
    "        'LF_NU': frequency_domain_features_anlysis['lfnu'],\n",
    "        'HF': frequency_domain_features_anlysis['hf'], \n",
    "        'HF_PCT': frequency_domain_features_anlysis['hf']*100 / frequency_domain_features_anlysis['total_power'],\n",
    "        'HF_NU': frequency_domain_features_anlysis['hfnu'],\n",
    "        'TP': frequency_domain_features_anlysis['total_power'], \n",
    "        'LF_HF': frequency_domain_features_anlysis['lf_hf_ratio'],\n",
    "        'HF_LF': 1/frequency_domain_features_anlysis['lf_hf_ratio'],\n",
    "        'sampen': sampen_value['sampen']\n",
    "    }\n",
    "    return hrv_features\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# rr_intervals_example = [1000, 1050, 1100, 1000, 950, 1050, 1100, 1000, 950, 1050]\n",
    "# hrv_result = calculate_hrv_features_pyhrv(rr_intervals_example)\n",
    "# print(hrv_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 13\n",
      "Begin converting candidate2_HRV_2023-04-28_cycling_7.0.csv\n",
      "Length of file:  12307\n",
      "Expected convertion lenght:  614\n",
      "Complete candidate2_HRV_2023-04-28_cycling_7.0.csv\n",
      "\n",
      "2 of 13\n",
      "Begin converting candidate2_HRV_2023-05-28_cycling_7.0.csv\n",
      "Length of file:  14035\n",
      "Expected convertion lenght:  606\n",
      "Complete candidate2_HRV_2023-05-28_cycling_7.0.csv\n",
      "\n",
      "3 of 13\n",
      "Begin converting candidate2_HRV_2023-06-20_cycling_7.0.csv\n",
      "Length of file:  11348\n",
      "Expected convertion lenght:  569\n",
      "Complete candidate2_HRV_2023-06-20_cycling_7.0.csv\n",
      "\n",
      "4 of 13\n",
      "Begin converting candidate2_HRV_2023-06-24_cycling_7.0.csv\n",
      "Length of file:  11525\n",
      "Expected convertion lenght:  582\n",
      "Complete candidate2_HRV_2023-06-24_cycling_7.0.csv\n",
      "\n",
      "5 of 13\n",
      "Begin converting candidate2_HRV_2023-07-20_cycling_7.0.csv\n",
      "Length of file:  10150\n",
      "Expected convertion lenght:  415\n",
      "Complete candidate2_HRV_2023-07-20_cycling_7.0.csv\n",
      "\n",
      "6 of 13\n",
      "Begin converting candidate2_HRV_2023-07-27_running_7.0.csv\n",
      "Length of file:  6134\n",
      "Expected convertion lenght:  251\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m window \u001b[38;5;241m=\u001b[39m txt_data\u001b[38;5;241m.\u001b[39miloc[i:i\u001b[38;5;241m+\u001b[39mwindow_size]\n\u001b[0;32m     56\u001b[0m window_data\u001b[38;5;241m=\u001b[39mwindow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhrv\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m---> 58\u001b[0m hrv_sample \u001b[38;5;241m=\u001b[39m calculate_hrv_features_pyhrv(window_data)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Extract values from the dictionary\u001b[39;00m\n\u001b[0;32m     61\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(hrv_sample\u001b[38;5;241m.\u001b[39mvalues())\n",
      "Cell \u001b[1;32mIn[3], line 48\u001b[0m, in \u001b[0;36mcalculate_hrv_features_pyhrv\u001b[1;34m(rr_intervals)\u001b[0m\n\u001b[0;32m     32\u001b[0m sampen_value\u001b[38;5;241m=\u001b[39m get_sampen(rr_intervals_ms)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# higuci_value = hfda.measure(rr_intervals, 5)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Combine all features into a dictionary\u001b[39;00m\n\u001b[0;32m     37\u001b[0m hrv_features \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMEAN_RR\u001b[39m\u001b[38;5;124m'\u001b[39m: time_domain_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnni_mean\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMEDIAN_RR\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmedian(rr_intervals),\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSDRR\u001b[39m\u001b[38;5;124m'\u001b[39m: time_domain_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msdnn\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSS\u001b[39m\u001b[38;5;124m'\u001b[39m: time_domain_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmssd\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSDSD\u001b[39m\u001b[38;5;124m'\u001b[39m: sdsd_feature[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msdsd\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSDRR_RMSSD\u001b[39m\u001b[38;5;124m'\u001b[39m: time_domain_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msdnn\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m time_domain_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmssd\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHR\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m60000\u001b[39m \u001b[38;5;241m/\u001b[39m time_domain_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnni_mean\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpNN25\u001b[39m\u001b[38;5;124m'\u001b[39m: time_domain_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpnn25\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpNN50\u001b[39m\u001b[38;5;124m'\u001b[39m: time_domain_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpnn50\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSD1\u001b[39m\u001b[38;5;124m'\u001b[39m: nonlinear\u001b[38;5;241m.\u001b[39mpoincare(rr_intervals_ms)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msd1\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSD2\u001b[39m\u001b[38;5;124m'\u001b[39m: nonlinear\u001b[38;5;241m.\u001b[39mpoincare(rr_intervals_ms)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msd2\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKURT\u001b[39m\u001b[38;5;124m'\u001b[39m: kurt_feature,\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSKEW\u001b[39m\u001b[38;5;124m'\u001b[39m: skew_feature,\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVLF\u001b[39m\u001b[38;5;124m'\u001b[39m: frequency_domain_features_anlysis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvlf\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVLF_PCT\u001b[39m\u001b[38;5;124m'\u001b[39m: frequency_domain_features_anlysis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvlf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m/\u001b[39m frequency_domain_features_anlysis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_power\u001b[39m\u001b[38;5;124m'\u001b[39m],  \n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLF\u001b[39m\u001b[38;5;124m'\u001b[39m: frequency_domain_features_anlysis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlf\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLF_PCT\u001b[39m\u001b[38;5;124m'\u001b[39m: frequency_domain_features_anlysis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m/\u001b[39m frequency_domain_features_anlysis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_power\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLF_NU\u001b[39m\u001b[38;5;124m'\u001b[39m: frequency_domain_features_anlysis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlfnu\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHF\u001b[39m\u001b[38;5;124m'\u001b[39m: frequency_domain_features_anlysis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhf\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m     57\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHF_PCT\u001b[39m\u001b[38;5;124m'\u001b[39m: frequency_domain_features_anlysis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m/\u001b[39m frequency_domain_features_anlysis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_power\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHF_NU\u001b[39m\u001b[38;5;124m'\u001b[39m: frequency_domain_features_anlysis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhfnu\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m: frequency_domain_features_anlysis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_power\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m     60\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLF_HF\u001b[39m\u001b[38;5;124m'\u001b[39m: frequency_domain_features_anlysis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlf_hf_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHF_LF\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mfrequency_domain_features_anlysis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlf_hf_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampen\u001b[39m\u001b[38;5;124m'\u001b[39m: sampen_value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampen\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     63\u001b[0m }\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hrv_features\n",
      "File \u001b[1;32mc:\\Users\\Olsen\\anaconda3\\Lib\\site-packages\\pyhrv\\nonlinear.py:186\u001b[0m, in \u001b[0;36mpoincare\u001b[1;34m(nni, rpeaks, show, figsize, ellipse, vectors, legend, marker, mode)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# Show plot\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show:\n\u001b[1;32m--> 186\u001b[0m \tplt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# Output\u001b[39;00m\n\u001b[0;32m    189\u001b[0m args \u001b[38;5;241m=\u001b[39m (fig, sd1, sd2, sd2\u001b[38;5;241m/\u001b[39msd1, area)\n",
      "File \u001b[1;32mc:\\Users\\Olsen\\anaconda3\\Lib\\site-packages\\matplotlib\\pyplot.py:446\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    445\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_backend_mod()\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Olsen\\anaconda3\\Lib\\site-packages\\matplotlib\\backend_bases.py:3609\u001b[0m, in \u001b[0;36m_Backend.show\u001b[1;34m(cls, block)\u001b[0m\n\u001b[0;32m   3607\u001b[0m         manager\u001b[38;5;241m.\u001b[39mshow()  \u001b[38;5;66;03m# Emits a warning for non-interactive backend.\u001b[39;00m\n\u001b[0;32m   3608\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m NonGuiException \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m-> 3609\u001b[0m         _api\u001b[38;5;241m.\u001b[39mwarn_external(\u001b[38;5;28mstr\u001b[39m(exc))\n\u001b[0;32m   3610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmainloop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('C:/Users/Olsen/Desktop/Masteroppgave/Data/fitfiler/candidate1/HRV_export/convertion')\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "files = glob.glob('*.csv')  # Adjust the path as needed\n",
    "\n",
    "# # Function to compute HRV features on a 5-minute moving window\n",
    "# def compute_hrv_features(ibis):\n",
    "#     hrv_sample = td.time_domain(ibis)\n",
    "#     return hrv_sample['nni_mean']\n",
    "\n",
    "\n",
    "# result=pd.DataFrame({'mean_RR':[], 'file': [], 'candidate': [], 'feeling': []})\n",
    "file_number = 1\n",
    "\n",
    "for file in files:     \n",
    "    file_name = str(file)\n",
    "    print(f'{file_number} of {len(files)}')\n",
    "    print(f'Begin converting {file_name}')\n",
    "    output_file = file_name[:-4] + '_features.txt'\n",
    "\n",
    "    txt_data = pd.read_csv(file, sep=',', header='infer')  \n",
    "    txt_data = txt_data[240:len(txt_data)-240]\n",
    "    txt_data['timestamp'] = np.array(txt_data['timestamp'])\n",
    "    txt_feeling = np.array(txt_data['feeling'])\n",
    "\n",
    "    print('Length of file: ', len(txt_data))\n",
    "\n",
    "    # Assuming your time_elapsed is in seconds\n",
    "    fs = 1 / np.mean(np.diff(txt_data['timestamp']))\n",
    "\n",
    "\n",
    "    # Initialize variables\n",
    "    window_size = int(fs) * 60 * 5  # 5 minutes in minuttes\n",
    "    num_samples = len(txt_data['hrv'])\n",
    "    hrv_samples = []\n",
    "    temp_result=pd.DataFrame()\n",
    "\n",
    "\n",
    "    print('Expected convertion lenght: ', int((len(txt_data)-window_size+1)/(fs*10)))\n",
    "\n",
    "\n",
    "    total = calculate_hrv_features_pyhrv(txt_data['hrv'])\n",
    "    keys = list(total.keys())\n",
    "    header_string = ', '.join(map(str, keys))\n",
    "    header_string_all = 'File, ' + header_string + ', Feeling'\n",
    "    with open(output_file, 'a') as file1:\n",
    "            file1.write(header_string_all + '\\n')  # Add a newline after each set of values\n",
    "\n",
    "\n",
    "    # Iterate through the IBI array with a 5-minute moving window\n",
    "    for i in range(0, num_samples - window_size + 1, int(fs*10)):\n",
    "        window = txt_data.iloc[i:i+window_size]\n",
    "        window_data=window['hrv']*1000\n",
    "\n",
    "        hrv_sample = calculate_hrv_features_pyhrv(window_data)\n",
    "\n",
    "        # Extract values from the dictionary\n",
    "        values = list(hrv_sample.values())\n",
    "\n",
    "        # Convert values to a string\n",
    "        values_string = ', '.join(map(str, values))\n",
    "        values_string_all = file_name[:-4] + ', ' + values_string + ', ' + str(txt_feeling[0])\n",
    "\n",
    "        # Open the output file in append mode and write the values string to it\n",
    "        with open(output_file, 'a') as file1:\n",
    "            file1.write(values_string_all + '\\n')  # Add a newline after each set of values\n",
    "\n",
    "    file_number += 1\n",
    "    print(f'Complete {file_name}')\n",
    "    print('')\n",
    "            \n",
    "\n",
    "print(\"----------------------\")\n",
    "print('SUCCESS! All files in folder converted')\n",
    "print(\"----------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

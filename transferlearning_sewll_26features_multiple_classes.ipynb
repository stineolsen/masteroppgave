{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "from scipy.stats import randint\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL\n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/Olsen/Desktop/Masteroppgave/Code/Swell/')\n",
    "\n",
    "# new_model = tf.keras.models.load_model('forTransferL.h5')\n",
    "# #model.layers[0].trainable = False\n",
    "# #x = model.layers[10].output\n",
    "# new_model.summary()\n",
    "\n",
    "# Load the pre-trained model\n",
    "pretrained_model = load_model('swell_model.h5')\n",
    "pretrained_model = load_model('swell_model_tree_classes.h5')\n",
    "\n",
    "# # Display the summary of the pre-trained model\n",
    "# pretrained_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date,timestamp,hrv,dfa,sport,feeling,rpe\n",
    "\n",
    "def replace_feeling(value):\n",
    "    if value >= 6:\n",
    "        return 1\n",
    "    elif value == 5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "\n",
    "# def replace_feeling(value):\n",
    "#     if value >= 5:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "\n",
    "# Function to load and preprocess data from a single file\n",
    "def load_and_preprocess(file_path, session):\n",
    "    df = pd.read_csv(file_path, sep=', ')\n",
    "\n",
    "    df['Feeling'] = df['Feeling'].apply(lambda x: replace_feeling(x))\n",
    "\n",
    "    X = df[['MEAN_RR', 'MEDIAN_RR', 'SDRR', 'RMSS', 'SDSD', 'SDRR_RMSSD', 'HR', 'pNN25', 'pNN50', 'SD1', 'SD2', 'KURT', 'SKEW', 'VLF', 'VLF_PCT', 'LF', 'LF_PCT', 'LF_NU', 'HF', 'HF_PCT', 'HF_NU', 'TP', 'LF_HF', 'HF_LF', 'sampen']]\n",
    "    y = df['Feeling']\n",
    "    return X, y\n",
    "\n",
    "# Function to load and preprocess data from multiple files in a folder\n",
    "def load_data_from_folder(folder_path):\n",
    "    X_all, y_all = [], []\n",
    "\n",
    "    session = 1\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            X, y = load_and_preprocess(file_path, session)\n",
    "            X_all.append(X)\n",
    "            y_all.append(y)\n",
    "            session += 1\n",
    "\n",
    "\n",
    "    X_test = np.vstack(X_all)\n",
    "    y_all = np.concatenate(y_all)\n",
    "\n",
    "    return X_all, y_all\n",
    "\n",
    "def folder_to_csv_file(folder, output_file):\n",
    "\n",
    "    X_all = pd.DataFrame()\n",
    "\n",
    "    for file_name in os.listdir(folder):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder, file_name)\n",
    "            df = pd.read_csv(file_path, sep=', ')\n",
    "            df['Feeling'] = df['Feeling'].apply(lambda x: replace_feeling(x))\n",
    "            \n",
    "            # pd.DataFrame.to_csv(df)\n",
    "            X_all = pd.concat([X_all, df])\n",
    "            # session += 1\n",
    "\n",
    "    X_all.to_csv(output_file, index=False)\n",
    "    return X_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('C:/Users/Olsen/Desktop/Masteroppgave/Data/fitfiler/candidate1/HRV_export/features_complete')\n",
    "\n",
    "\n",
    "# train_folder = \"C:/Users/Olsen/Desktop/Masteroppgave/Data/fitfiler/candidate1/HRV_export/features_complete/train/\"\n",
    "# train = pd.DataFrame()\n",
    "# # candidate1_HRV_2023-05-18_rowing_3.0_features\n",
    "# for file_name in os.listdir(train_folder):\n",
    "#     if file_name.endswith(\".txt\"):\n",
    "#         #print(file_name[-16])\n",
    "#         if file_name[-16] not in [\"5\", \"7\", \"3\"]:\n",
    "#             #print(\"not middle\")\n",
    "#             file_path = os.path.join(train_folder, file_name)\n",
    "#             df = pd.read_csv(file_path, sep=', ')\n",
    "#             # df['Feeling'] = df['Feeling'].apply(lambda x: replace_feeling(x))\n",
    "            \n",
    "#             # pd.DataFrame.to_csv(df)\n",
    "#             train = pd.concat([train, df])\n",
    "\n",
    "# train.to_csv('train.csv', index=False)\n",
    "\n",
    "# # folder_to_csv_file(train_folder, 'train.csv')\n",
    "\n",
    "# test_folder = \"C:/Users/Olsen/Desktop/Masteroppgave/Data/fitfiler/candidate1/HRV_export/features_complete/test/\"\n",
    "# test = pd.DataFrame()\n",
    "\n",
    "# for file_name in os.listdir(test_folder):\n",
    "#     if file_name.endswith(\".txt\"):\n",
    "#         if file_name[-16] not in [\"5\", \"7\", \"3\"]:\n",
    "#             file_path = os.path.join(test_folder, file_name)\n",
    "#             df = pd.read_csv(file_path, sep=', ')\n",
    "#             # df['Feeling'] = df['Feeling'].apply(lambda x: replace_feeling(x))\n",
    "            \n",
    "#             # pd.DataFrame.to_csv(df)\n",
    "#             test = pd.concat([test, df])\n",
    "\n",
    "# test.to_csv('test.csv', index=False)\n",
    "\n",
    "# # folder_to_csv_file(test_folder, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_folder = \"C:/Users/Olsen/Desktop/Masteroppgave/Data/fitfiler/candidate1/HRV_export/features_complete/dataset_v3/\"\n",
    "all = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "for file_name in os.listdir(all_folder):\n",
    "\n",
    "    # all_file = str(file_name)\n",
    "    # print(all_file)\n",
    "    # print(all_file[-19])\n",
    "\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        if file_name[-19] not in [\"7\", \"3\"]:\n",
    "            file_path = os.path.join(all_folder, file_name)\n",
    "            df = pd.read_csv(file_path, sep=', ')\n",
    "            # df['Feeling'] = df['Feeling'].apply(lambda x: replace_feeling(x))\n",
    "            \n",
    "            # pd.DataFrame.to_csv(df)\n",
    "            all = pd.concat([all, df])\n",
    "\n",
    "all.to_csv('all_9and1.csv', index=False)\n",
    "\n",
    "train, test = train_test_split(all, random_state=42, test_size=0.25, train_size=0.75)\n",
    "# folder_to_csv_file(test_folder, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify the folder containing your CSV files\n",
    "# train_folder = \"C:/Users/Olsen/Desktop/Masteroppgave/Data/fitfiler/candidate2/csv_files\"\n",
    "\n",
    "# # Load and preprocess data from multiple files in the folder\n",
    "# X_train, y_train = load_data_from_folder(train_folder)\n",
    "\n",
    "\n",
    "# # Specify the folder containing your CSV files\n",
    "# test_folder = \"C:/Users/Olsen/Desktop/Masteroppgave/Data/fitfiler/candidate1/csv_files\"\n",
    "\n",
    "# # Load and preprocess data from multiple files in the folder\n",
    "# X_test, y_test = load_data_from_folder(test_folder)\n",
    "\n",
    "# print(X_train)\n",
    "# # print(X_test)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# # Reshape input data for LSTM\n",
    "# X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "# X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "# print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('C:/Users/Olsen/Desktop/Masteroppgave/Data/fitfiler/candidate1/csv_files')\n",
    "\n",
    "# train_folder = \"C:/Users/Olsen/Desktop/Masteroppgave/Data/fitfiler/candidate1/HRV_export/features_complete/\"\n",
    "\n",
    "# X_train, y_train = load_data_from_folder(train_folder)\n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_all = pd.read_csv('v1_olt_dataset.csv')\n",
    "# train, test = train_test_split(X_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test')\n",
    "\n",
    "# Verify the changes\n",
    "print(test['Feeling'].value_counts())\n",
    "print(test['Feeling'].size)\n",
    "print('')\n",
    "\n",
    "print('Train')\n",
    "\n",
    "# trainDataSet['condition'] = trainDataSet['condition'].replace({'interruption': 'stress', 'time pressure': 'stress'})\n",
    "\n",
    "# Verify the changes\n",
    "print(train['Feeling'].value_counts())\n",
    "print(train['Feeling'].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Feeling'] = train['Feeling'].apply(lambda x: replace_feeling(x))\n",
    "\n",
    "y_train = train['Feeling']\n",
    "\n",
    "y_train = pd.get_dummies(y_train)\n",
    "\n",
    "# y_train = df_mean_train['feeling']\n",
    "# labelencoder = LabelEncoder()\n",
    "# y_train = labelencoder.fit_transform(df_mean_train[\"feeling\"])\n",
    "print('Train')\n",
    "\n",
    "# trainDataSet['condition'] = trainDataSet['condition'].replace({'interruption': 'stress', 'time pressure': 'stress'})\n",
    "\n",
    "# Verify the changes\n",
    "print(train['Feeling'].value_counts())\n",
    "print(train['Feeling'].size)\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSamples = train.drop(['Feeling','File'], axis = 1)\n",
    "\n",
    "trainSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Feeling'] = test['Feeling'].apply(lambda x: replace_feeling(x))\n",
    "\n",
    "y_test = test['Feeling']\n",
    "y_test = pd.get_dummies(y_test)\n",
    "\n",
    "testlabels1 = test['Feeling']\n",
    "labelencoder = LabelEncoder()\n",
    "testLabels1 = labelencoder.fit_transform(test['Feeling'])\n",
    "\n",
    "print('Test')\n",
    "\n",
    "# Verify the changes\n",
    "print(test['Feeling'].value_counts())\n",
    "print(test['Feeling'].size)\n",
    "print('')\n",
    "\n",
    "# y_train = df_mean_train['feeling']\n",
    "# labelencoder = LabelEncoder()\n",
    "# y_train = labelencoder.fit_transform(df_mean_train[\"feeling\"])\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSamples = test.drop(['Feeling','File'], axis = 1)\n",
    "\n",
    "testSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the summary of the pre-trained model\n",
    "pretrained_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # input_shape = (8,)\n",
    "\n",
    "# # Create a new model for transfer learning\n",
    "# transfer_model = Sequential()\n",
    "\n",
    "# # transfer_model.add(Dense(8, activation='sigmoid', input_shape=input_shape, name='dense_input'))\n",
    "\n",
    "# for layer in pretrained_model.layers[:-1]:\n",
    "#     transfer_model.add(layer)\n",
    "\n",
    "\n",
    "# transfer_model.add(Dense(3, activation='softmax', name='output_layer'))  # Modify activation based on your problem\n",
    "\n",
    "\n",
    "# for layer in pretrained_model.layers[:-2]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "\n",
    "# transfer_model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# transfer_model.compile(optimizer='Adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# transfer_model.summary()\n",
    "\n",
    "# # transfer_model.fit(trainSamples, y_train, epochs=40, batch_size=32, validation_split=0.1)\n",
    "# transfer = transfer_model.fit(trainSamples, y_train, validation_split=0.1 ,batch_size=100, epochs=100, verbose=1, shuffle=True)\n",
    "# # early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# pretrained = pretrained_model.fit(trainSamples, y_train, validation_split=0.1,  batch_size=100, epochs=100, verbose=1, shuffle=True)\n",
    "# # transfer_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "\n",
    "# # transfer_model.save('transfer_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.applications import YourPretrainedModel  # Replace with the actual pre-trained model you're using\n",
    "\n",
    "# Assuming input_shape is defined based on your specific problem\n",
    "input_shape = (your_input_shape_here)\n",
    "\n",
    "# Load the pre-trained model\n",
    "pretrained_model = YourPretrainedModel(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Create a new model using the pre-trained weights\n",
    "pretrained_only_model = Sequential()\n",
    "pretrained_only_model.add(pretrained_model)\n",
    "pretrained_only_model.add(Dense(3, activation='softmax', name='output_layer'))  # Modify activation based on your problem\n",
    "\n",
    "# Compile the model\n",
    "pretrained_only_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Modify loss based on your problem\n",
    "\n",
    "# Display the model summary\n",
    "pretrained_only_model.summary()\n",
    "\n",
    "# Train the model on your data\n",
    "history = pretrained_only_model.fit(trainSamples, y_train, validation_split=0.1, batch_size=100, epochs=100, verbose=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(pretrained.history['accuracy'])\n",
    "plt.plot(pretrained.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(transfer.history['accuracy'])\n",
    "plt.plot(transfer.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a new model for transfer learning\n",
    "# transfer_model = Sequential()\n",
    "\n",
    "# # Add a Flatten layer to reshape the input\n",
    "# # transfer_model.add(Flatten(input_shape=(1, 9)))\n",
    "\n",
    "\n",
    "# # Add layers to the transfer model by iterating through the pre-trained model layers\n",
    "# for layer in pretrained_model.layers[:-1]:\n",
    "#     # Add a layer with the same configuration, excluding the input shape\n",
    "#     transfer_model.add(layer.__class__.from_config(layer.get_config()))\n",
    "\n",
    "# # Add a new output layer with the correct number of units for your specific problem\n",
    "# transfer_model.add(Dense(1, activation='sigmoid'))  # Modify activation based on your problem\n",
    "\n",
    "\n",
    "# # Compile the transfer model\n",
    "# transfer_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Display the summary of the transfer model\n",
    "# transfer_model.summary()\n",
    "\n",
    "# # Assuming your training data is stored in X_train and labels in y_train\n",
    "# # Make sure to adjust the parameters in fit() according to your requirements\n",
    "# transfer_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = pretrained_model.evaluate(testSamples,  y_test, verbose=2)\n",
    "# print('\\nTest loss: ', test_loss)\n",
    "# print('\\nTest accuracy: ', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = transfer_model.evaluate(testSamples,  y_test, verbose=2)\n",
    "# print('\\nTest loss: ', test_loss)\n",
    "# print('\\nTest accuracy: ', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "\n",
    "### Squential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Make predictions\n",
    "# probability_model = tf.keras.Sequential([transfer_model, tf.keras.layers.Softmax()])\n",
    "# y_predict = probability_model.predict(testSamples)\n",
    "# # predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "y_predict = pretrained_model.predict(testSamples)\n",
    "print(y_predict)\n",
    "y_pred = np.argmax(y_predict, axis = -1)\n",
    "\n",
    "\n",
    "t =pd.DataFrame(y_pred)\n",
    "t.value_counts()\n",
    "# df_mean_test.feeling.value_counts()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_pred,testLabels1)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "accuracy = accuracy_score(testLabels1, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "report = classification_report(testLabels1, y_pred, zero_division=np.nan)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# confusion = confusion_matrix(testLabels1, y_pred) # add normalize='pred' if want %\n",
    "# print('Confusion Matrix\\n')\n",
    "# print(confusion)\n",
    "\n",
    "ax = sns.heatmap(confusion, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title(' Confusion Matrix with labels\\n\\n')\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Make predictions\n",
    "# probability_model = tf.keras.Sequential([transfer_model, tf.keras.layers.Softmax()])\n",
    "# y_predict = probability_model.predict(testSamples)\n",
    "# # predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "# y_predict = transfer_model.predict(testSamples)\n",
    "# print(y_predict)\n",
    "# y_pred = np.argmax(y_predict, axis = -1)\n",
    "\n",
    "\n",
    "# t =pd.DataFrame(y_pred)\n",
    "# t.value_counts()\n",
    "# # df_mean_test.feeling.value_counts()\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# confusion = confusion_matrix(y_pred,testLabels1)\n",
    "# print('Confusion Matrix\\n')\n",
    "# print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = accuracy_score(testLabels1, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# report = classification_report(testLabels1, y_pred, zero_division=np.nan)\n",
    "# print(\"Classification Report:\")\n",
    "# print(report)\n",
    "\n",
    "# confusion = confusion_matrix(testLabels1, y_pred) # add normalize='pred' if want %\n",
    "# print('Confusion Matrix\\n')\n",
    "# print(confusion)\n",
    "\n",
    "# ax = sns.heatmap(confusion, annot=True, cmap='Blues')\n",
    "\n",
    "# ax.set_title(' Confusion Matrix with labels\\n\\n')\n",
    "# ax.set_xlabel('\\nPredicted Values')\n",
    "# ax.set_ylabel('Actual Values ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=15, min_samples_leaf=1, random_state=42)\n",
    "rf_classifier.fit(trainSamples, y_train)\n",
    "y_pred = rf_classifier.predict(testSamples)\n",
    "y_roundedValue = np.argmax(y_pred, axis = -1)\n",
    "# print(y_pred)\n",
    "accuracy = accuracy_score(testLabels1, y_roundedValue)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "report = classification_report(testLabels1, y_roundedValue)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "result = confusion_matrix(testLabels1, y_roundedValue)\n",
    "\n",
    "ax = sns.heatmap(result, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title(' Confusion Matrix with labels\\n\\n')\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ')\n",
    "\n",
    "\n",
    "\n",
    "# result = confusion_matrix(y_test, y_pred , normalize='pred')\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=result)\n",
    "\n",
    "# disp.plot(cmap=plt.cm.Blues)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Evaluate the model\n",
    "# loss = transfer_model.evaluate(testSamples, y_test)\n",
    "# print(f\"Test Loss: {loss}\")\n",
    "\n",
    "# test_loss, test_acc = transfer_model.evaluate(testSamples,  y_test, verbose=2)\n",
    "# print('\\nTest loss: ', test_loss)\n",
    "# print('\\nTest accuracy: ', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(trainSamples, y_train)\n",
    "y_pred = rf_classifier.predict(trainSamples)\n",
    "y_roundedValue = np.argmax(y_pred, axis = -1)\n",
    "\n",
    "accuracy = accuracy_score(testLabels1, y_roundedValue)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "report = classification_report(testLabels1, y_roundedValue)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "\n",
    "result = confusion_matrix(testLabels1, y_roundedValue)\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=result)\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors=1000)\n",
    "knn_classifier.fit(trainSamples, y_train)\n",
    "y_pred = rf_classifier.predict(trainSamples)\n",
    "y_roundedValue = np.argmax(y_pred, axis = -1)\n",
    "\n",
    "accuracy = accuracy_score(testLabels1, y_roundedValue)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "report = classification_report(testLabels1, y_roundedValue)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "\n",
    "result = confusion_matrix(testLabels1, y_roundedValue)\n",
    "print(classification_report(testLabels1, y_roundedValue))\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=result)\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_classifier.fit(trainSamples, y_train)\n",
    "y_pred = rf_classifier.predict(trainSamples)\n",
    "y_roundedValue = np.argmax(y_pred, axis = -1)\n",
    "\n",
    "accuracy = accuracy_score(testLabels1, y_roundedValue)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "report = classification_report(testLabels1, y_roundedValue)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "\n",
    "result = confusion_matrix(testLabels1, y_roundedValue)\n",
    "\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=result)\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('forTransferL.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
